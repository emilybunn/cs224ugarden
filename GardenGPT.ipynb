{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gliwj0Xct_Wl"
      },
      "outputs": [],
      "source": [
        "!pip install numpy\n",
        "!pip install scipy\n",
        "!pip install matplotlib\n",
        "!pip install scikit-learn\n",
        "!pip install nltk\n",
        "!pip install pytest\n",
        "!pip install pandas\n",
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install streamlit\n",
        "!pip install openai\n",
        "!pip install plotly\n",
        "!pip install statistics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import openai\n",
        "from transformers import pipeline\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import statistics\n",
        "\n",
        "model = \"text-davinci-003\"\n",
        "\n",
        "openai.api_key = \"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\""
      ],
      "metadata": {
        "id": "Bi2RKJq4atnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the dataset with garden path sentences."
      ],
      "metadata": {
        "id": "lz6kqpureU8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gardenPathDataset = pd.read_csv(\"GP_BERT.csv\")\n",
        "\n",
        "gardenPathSentences = []\n",
        "\n",
        "for row in range(len(gardenPathDataset['Code'])):\n",
        "  code = gardenPathDataset['Code'][row]\n",
        "  if code[:2] == 'GP':\n",
        "    context = gardenPathDataset['Context'][row]\n",
        "    question = gardenPathDataset['Question'][row]\n",
        "    answer = gardenPathDataset['Answer'][row]\n",
        "    gardenPathSentences.append([code, context, question, answer])"
      ],
      "metadata": {
        "id": "GnEA_o-NJ4NC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt the OpenAI model as selected above on different questions."
      ],
      "metadata": {
        "id": "2lFX9PPCeX7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline prompting.\n",
        "\n",
        "for i in range(len(gardenPathSentences)):\n",
        "  sentence = gardenPathSentences[i]\n",
        "  prompt = sentence[1] + ' ' + sentence[2]\n",
        "  response = openai.Completion.create(engine=model, prompt=prompt, max_tokens=50)\n",
        "  sentence.append(response.choices[0].text)"
      ],
      "metadata": {
        "id": "224dmt3QYbt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chain of thought prompting.\n",
        "\n",
        "for i in range(len(gardenPathSentences)):\n",
        "  sentence = gardenPathSentences[i]\n",
        "  prompt = 'Q: The driver worried about the dispatcher handed a pink slip. Who was handed a pink slip? A: The dispatcher. Q:' + sentence[1] + ' ' + sentence[2] + 'A:'\n",
        "  response = openai.Completion.create(engine=model, prompt=prompt, max_tokens=50)\n",
        "  sentence.append(response.choices[0].text)"
      ],
      "metadata": {
        "id": "80kyHUIGa-zS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Context prompting.\n",
        "\n",
        "prompt = \"The child read a story hugged the nanny. What did the child do?\"\n",
        "response = openai.Completion.create(engine=model, prompt=prompt, max_tokens=50)\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Odkn1J-G4T2B",
        "outputId": "477426ab-e001-4134-95bb-2976d46014ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject text_completion id=cmpl-7PmL5hqhTNE8PelWIx60WhRU6dbjd at 0x7f5f1f4d1cb0> JSON: {\n",
              "  \"id\": \"cmpl-7PmL5hqhTNE8PelWIx60WhRU6dbjd\",\n",
              "  \"object\": \"text_completion\",\n",
              "  \"created\": 1686378371,\n",
              "  \"model\": \"text-davinci-003\",\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"text\": \"\\n\\nThe child gave the nanny a hug after reading the story.\",\n",
              "      \"index\": 0,\n",
              "      \"logprobs\": null,\n",
              "      \"finish_reason\": \"stop\"\n",
              "    }\n",
              "  ],\n",
              "  \"usage\": {\n",
              "    \"prompt_tokens\": 16,\n",
              "    \"completion_tokens\": 15,\n",
              "    \"total_tokens\": 31\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save output into a .csv file.\n",
        "\n",
        "GP_GPT3 = pd.DataFrame(gardenPathSentences)\n",
        "\n",
        "GP_GPT3.columns =['Type', 'Context', 'Question', 'Answer', 'Output']\n",
        "\n",
        "GP_GPT3.to_csv('GP_GPT3 CoT for PE.csv', index=False, header=False)\n",
        "\n",
        "df = GP_GPT3"
      ],
      "metadata": {
        "id": "CMGVXu7uYtuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternatively: Read in an old file.\n",
        "\n",
        "GP_GPT3 = pd.read_csv('GP_GPT3 CoT for AM.csv')\n",
        "\n",
        "GP_GPT3.columns = ['Type', 'Context', 'Question', 'Answer', 'Output']\n",
        "\n",
        "df = GP_GPT3"
      ],
      "metadata": {
        "id": "3AZT6GCci8s8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to plot."
      ],
      "metadata": {
        "id": "bSffdSy5eeDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stacked_plot(answers_df):\n",
        "    colors = {\"Garden Path\": \"#DDAA33\", \"Local Coherence\": \"#BB5566\"}\n",
        "    patterns = {\"Ambiguous\": \"\", \"Unambiguous\": \".\"}\n",
        "\n",
        "    #print(answers_df)\n",
        "    answers_df['Question Type'] = pd.Categorical(answers_df['Question Type'], [\"Agent Matrix\", \"Patient Matrix\", \"Ambiguous Argument\", \"Matrix Action\", \"Embedded Action\"])\n",
        "    answers_df = answers_df.sort_values(['Question Type', 'Correct'],ascending=[True, True])\n",
        "    print(answers_df)\n",
        "\n",
        "    temp = answers_df.iloc[::4][['Correct', 'Question Type', 'Ambiguity', 'Structure']]\n",
        "    # fig = go.Figure(go.Bar(x=temp['Question Type'], y = temp['Correct'], color=temp['Structure'], color_discrete_sequence=temp['Structure'].map(colors), pattern_shape=temp['Ambiguity'], pattern_shape_sequence=temp['Ambiguity'].map(patterns)))\n",
        "\n",
        "    # testing1 = {'title': 'Baseline Evaluation of GPT-3'}\n",
        "\n",
        "    fig = go.Figure(go.Bar(x=temp['Question Type'], y = temp['Correct'], marker_color=temp['Structure'].map(colors), marker_pattern={\"shape\": temp['Ambiguity'].map(patterns)}))\n",
        "\n",
        "    for i in range(1,4):\n",
        "        temp_prev = answers_df.iloc[i-1::4][['Correct', 'Question Type', 'Ambiguity', 'Structure']].reset_index()\n",
        "        temp = answers_df.iloc[i::4][['Correct', 'Question Type', 'Ambiguity', 'Structure']].reset_index()\n",
        "        temp['Correct_edit'] = temp['Correct']-temp_prev['Correct']\n",
        "        #fig.add_trace(go.Bar(x=temp['Question Type'], y = temp['Correct_edit'],\n",
        "        #marker_color=temp['Structure'].map(colors), marker_pattern={\"shape\": temp['Ambiguity'].map(patterns)}))\n",
        "        fig.add_trace(go.Bar(x=temp['Question Type'], y = temp['Correct'],\n",
        "        marker_color=temp['Structure'].map(colors), marker_pattern={\"shape\": temp['Ambiguity'].map(patterns)}))\n",
        "\n",
        "    fig.update_layout(\n",
        "        #barmode='stack',\n",
        "        font_family=\"Times New Roman\",\n",
        "        font_color =\"black\",\n",
        "        font_size=24,\n",
        "        title=\"CoT w/ Ambiguous Argument Evaluation of GPT-3\"\n",
        "        #plot_bgcolor='rgba(0,0,0,0)',\n",
        "        #gridcolor='gray'\n",
        "    )\n",
        "\n",
        "    fig.update_xaxes(title_text='Question Type',\n",
        "        title_font_family=\"Times New Roman\",\n",
        "        title_font_color =\"black\",\n",
        "        title_font_size=24,\n",
        "    )\n",
        "\n",
        "    fig.update_yaxes(title_text='Accuracy',\n",
        "        title_font_family=\"Times New Roman\",\n",
        "        title_font_color =\"black\",\n",
        "        title_font_size=24,\n",
        "    )\n",
        "\n",
        "\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "mX2T5FSTW3jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract the answers from the model's output and score it."
      ],
      "metadata": {
        "id": "7uLCzkrpefT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "QAer = pipeline('question-answering')\n",
        "scores = {v: [] for v in df.Type.unique()}\n",
        "answers = {v: [] for v in df.Type.unique()}\n",
        "out = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "  QA_input = {\n",
        "      'question': row['Question'],\n",
        "      'context': row['Output']\n",
        "  }\n",
        "  res = QAer(QA_input)\n",
        "  scores[row['Type']].append(res['score'])\n",
        "\n",
        "  if res['answer'].strip(\".\").lower() in row['Answer'].split('\\n'):\n",
        "        correct = 1\n",
        "  else:\n",
        "      correct = 0\n",
        "  answers[row['Type']].append(correct)\n",
        "  out.append([row['Type'], row['Context'], row['Question'], row['Answer'], res['answer'], res['score'], correct])\n",
        "\n",
        "final = {v: statistics.mean(scores[v]) for v in scores.keys()}\n",
        "final_ans = {v: statistics.mean(answers[v]) for v in answers.keys()}\n",
        "answers_df = pd.DataFrame(final_ans.items(), columns=['Type', 'Correct']).sort_values(by=['Correct'])\n",
        "scores_df = pd.DataFrame(final.items(), columns=['Type', 'Score']).sort_values(by=['Score'])\n",
        "\n",
        "names = {\"AM\": \"Agent Matrix\", \"PM\": \"Patient Matrix\", \"PE\": \"Ambiguous Argument\", \"A1\": \"Matrix Action\", \"A2\": \"Embedded Action\", \"U\": \"Unambiguous\", \"A\": \"Ambiguous\", \"GP\": \"Garden Path\", \"LC\": \"Local Coherence\"}\n",
        "answers_df['Question Type'] = answers_df['Type'].str.extract(r'-([A-Z0-9]*)$')\n",
        "answers_df['Ambiguity'] = answers_df['Type'].str.extract(r'-([A-Z0-9]*)-')\n",
        "answers_df['Structure'] = answers_df['Type'].str.extract(r'^([A-Z0-9]*)-')\n",
        "answers_df['Question Type'] = answers_df['Question Type'].map(names)\n",
        "answers_df['Ambiguity'] = answers_df['Ambiguity'].map(names)\n",
        "answers_df['Structure'] = answers_df['Structure'].map(names)\n",
        "answers_df['Question Type'] = pd.Categorical(answers_df['Question Type'], [\"Agent Matrix\", \"Patient Matrix\", \"Ambiguous Argument\", \"Matrix Action\", \"Embedded Action\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZpzwF9aSuzl",
        "outputId": "5d360bb8-cf05-42de-b02f-5db26d331e86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stacked_plot(answers_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        },
        "id": "xox_7Iiaas6E",
        "outputId": "cddf870b-560b-4b6e-d5ef-d8f5dbb9c32e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Type  Correct       Question Type    Ambiguity    Structure\n",
            "0  GP-A-AM    0.850        Agent Matrix    Ambiguous  Garden Path\n",
            "4  GP-U-AM    0.925        Agent Matrix  Unambiguous  Garden Path\n",
            "5  GP-U-PM    0.900      Patient Matrix  Unambiguous  Garden Path\n",
            "1  GP-A-PM    0.925      Patient Matrix    Ambiguous  Garden Path\n",
            "2  GP-A-PE    0.750  Ambiguous Argument    Ambiguous  Garden Path\n",
            "6  GP-U-PE    0.950  Ambiguous Argument  Unambiguous  Garden Path\n",
            "3  GP-A-A1    0.175       Matrix Action    Ambiguous  Garden Path\n",
            "7  GP-U-A1    0.525       Matrix Action  Unambiguous  Garden Path\n",
            "8  GP-A-A2    0.425     Embedded Action    Ambiguous  Garden Path\n",
            "9  GP-U-A2    0.550     Embedded Action  Unambiguous  Garden Path\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"c9dbd6a0-695e-4b28-98b3-6f9c9517d698\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c9dbd6a0-695e-4b28-98b3-6f9c9517d698\")) {                    Plotly.newPlot(                        \"c9dbd6a0-695e-4b28-98b3-6f9c9517d698\",                        [{\"marker\":{\"color\":[\"#DDAA33\",\"#DDAA33\",\"#DDAA33\"],\"pattern\":{\"shape\":[\"\",\"\",\"\"]}},\"x\":[\"Agent Matrix\",\"Ambiguous Argument\",\"Embedded Action\"],\"y\":[0.85,0.75,0.425],\"type\":\"bar\"},{\"marker\":{\"color\":[\"#DDAA33\",\"#DDAA33\",\"#DDAA33\"],\"pattern\":{\"shape\":[\".\",\".\",\".\"]}},\"x\":[\"Agent Matrix\",\"Ambiguous Argument\",\"Embedded Action\"],\"y\":[0.925,0.95,0.55],\"type\":\"bar\"},{\"marker\":{\"color\":[\"#DDAA33\",\"#DDAA33\"],\"pattern\":{\"shape\":[\".\",\"\"]}},\"x\":[\"Patient Matrix\",\"Matrix Action\"],\"y\":[0.9,0.175],\"type\":\"bar\"},{\"marker\":{\"color\":[\"#DDAA33\",\"#DDAA33\"],\"pattern\":{\"shape\":[\"\",\".\"]}},\"x\":[\"Patient Matrix\",\"Matrix Action\"],\"y\":[0.925,0.525],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"font\":{\"family\":\"Times New Roman\",\"color\":\"black\",\"size\":24},\"title\":{\"text\":\"CoT w/ Ambiguous Argument Evaluation of GPT-3\"},\"xaxis\":{\"title\":{\"font\":{\"family\":\"Times New Roman\",\"color\":\"black\",\"size\":24},\"text\":\"Question Type\"}},\"yaxis\":{\"title\":{\"font\":{\"family\":\"Times New Roman\",\"color\":\"black\",\"size\":24},\"text\":\"Accuracy\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('c9dbd6a0-695e-4b28-98b3-6f9c9517d698');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sOi8vJkTjj12"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}